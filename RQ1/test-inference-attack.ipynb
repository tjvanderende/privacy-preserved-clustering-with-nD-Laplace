{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets._samples_generator import make_blobs\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X, y_true = make_blobs(n_samples=50, centers=4, n_features=2,\n",
    "                       cluster_std=0.60, random_state=0)\n",
    "\n",
    "X_scaled = pd.DataFrame(StandardScaler().fit_transform(X), columns=['X', 'Y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Calculates the empirical root mean squared error. algorithm is a function\n",
    "that takes in X and y and returns a model.'''\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def get_empirical_error(algorithm, X, y):\n",
    "    model = algorithm.fit(X)\n",
    "    mse = mean_squared_error(y, model.predict(X))\n",
    "    return sqrt(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import issparse, vstack\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "TRAIN = 100\n",
    "TEST = 200\n",
    "\n",
    "def get_multipliers(errors, rmse):\n",
    "    zs = errors / rmse\n",
    "    return np.array([Logprob(-z**2 / 2, True) for z in zs])\n",
    "\n",
    "def gaussian_pdf(sd, x):\n",
    "    if sd <= 0:\n",
    "        raise ValueError('standard deviation must be positive but is {}'.format(sd))\n",
    "    else: #sd > 0\n",
    "        return np.e ** (-0.5*(x/sd)**2) / sd\n",
    "    \n",
    "def sklearn_invert(model, dist, X, y, target_cols, rmse):\n",
    "    assert X.shape[0] == y.shape[0] #check that X and y have compatible dimensions\n",
    "    \n",
    "    if issparse(X): #deal with sparse matrices correctly\n",
    "        stack = vstack\n",
    "    else:\n",
    "        stack = np.stack\n",
    "    \n",
    "    guesses = []\n",
    "    \n",
    "    assert len(target_cols) > 0\n",
    "    one_hot = (len(target_cols) > 1) #whether the target attribute was one-hot encoded (binary otherwise)\n",
    "    num_variants = len(target_cols) if one_hot else 2 #number of possible values of the target\n",
    "    \n",
    "    for i in range(X.shape[0]): #iterate over the rows of X and y\n",
    "        row_X = stack([X[i] for _ in range(num_variants)]) #create copies of X[i]\n",
    "        if one_hot:\n",
    "            row_X[:, target_cols] = np.eye(num_variants) #fill in with all possible values of target (one-hot encoded)\n",
    "        else: #fill in with all possible values of target (binary)\n",
    "            row_X[0, target_cols] = 0\n",
    "            row_X[1, target_cols] = 1\n",
    "        row_y = np.repeat(y[i], num_variants)\n",
    "        \n",
    "        errors = row_y - model.predict(row_X)\n",
    "        likelihood_scores = dist * get_multipliers(errors, rmse)\n",
    "        guess = np.where(likelihood_scores == max(likelihood_scores))[0][0] #an integer in range(num_variants)\n",
    "        guesses.append(guess)\n",
    "    \n",
    "    return np.array(guesses)\n",
    "def sklearn_do_inversion(model, dist, X, y, t, target_cols, rmse):\n",
    "    assert X.shape[0] == y.shape[0] == t.shape[0]\n",
    "    num_rows = X.shape[0]\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore', sparse.SparseEfficiencyWarning)\n",
    "        results = sklearn_invert(model, dist, X, y, target_cols, rmse)\n",
    "    num_correct = np.count_nonzero(results == t)\n",
    "    \n",
    "    return num_correct / num_rows\n",
    "def gaussian_pdf(sd, x):\n",
    "    if sd <= 0:\n",
    "        raise ValueError('standard deviation must be positive but is {}'.format(sd))\n",
    "    else: #sd > 0\n",
    "        return np.e ** (-0.5*(x/sd)**2) / sd\n",
    "    \n",
    "def sklearn_decide(errors, r_emp):\n",
    "    return np.where(abs(errors) < r_emp, TRAIN, TEST)\n",
    "\n",
    "def sklearn_inclusion(model, X, y, r_emp):\n",
    "    pred_vals = model.predict(X)\n",
    "    actual_vals = y\n",
    "    errors = actual_vals - pred_vals\n",
    "    return sklearn_decide(errors, r_emp)\n",
    "\n",
    "def sklearn_do_inclusion(model, X, y, r_emp):\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    num_rows = X.shape[0]\n",
    "    \n",
    "    results = sklearn_inclusion(model, X, y, r_emp)\n",
    "    num_train = np.count_nonzero(results == TRAIN)\n",
    "    \n",
    "    return num_train / num_rows\n",
    "\n",
    "def iterate_inclusion_and_write(algorithm, X, X_perturbed, y, r_emp):\n",
    "  \n",
    "  model = algorithm.fit(X)\n",
    "  model_p = clone(algorithm).fit(X_perturbed)\n",
    "  \n",
    "  #Calculate attribute inference accuracy\n",
    "  train_correct = sklearn_inclusion(model, X, y, r_emp)\n",
    "  test_correct = sklearn_inclusion(model_p, X_perturbed, y, r_emp)\n",
    "  \n",
    "  print(r_emp, train_correct, test_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fc7d5fe0e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.9086079144497976"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "algorithm = KMeans(n_clusters=8)  \n",
    "r_emp = get_empirical_error(algorithm, X, y_true) #root mean squared\n",
    "r_emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "from sympy import LambertW\n",
    "\n",
    "\n",
    "\n",
    "def addVectorToPoint(point, distance, angle):\n",
    "\tx1, y1 = point\n",
    "\tx2 = x1 + (distance * np.cos(angle))\n",
    "\ty2 = y1 + (distance * np.sin(angle))\n",
    "\treturn x2, y2\n",
    "    \n",
    "\n",
    "def inverseCumulativeGamma (eps, p): \n",
    "    x = (p - 1) / np.e\n",
    "    return -(LambertW(x) + 1)/eps\n",
    "\n",
    "def generate_laplace_noise(eps, x, y): \n",
    "    theta = np.random.rand()*np.pi*2\n",
    "    p = random.random()\n",
    "    r = inverseCumulativeGamma(eps, p) # draw radius distance\n",
    "    return addVectorToPoint([x, y], r, theta)\n",
    "\n",
    "\n",
    "def calculate_radius_with_noise(x0, n, epsilon): \n",
    "    \"\"\"\n",
    "        x0: Point to perturb\n",
    "        n: amount of points to generate\n",
    "        epsilon: privacy budget\n",
    "    \"\"\"\n",
    "    Z = []\n",
    "    total_dis = 0\n",
    "    for nm in range(0, n):\n",
    "        x1, y1 = x0\n",
    "        noise = generate_laplace_noise(epsilon, x1, y1)\n",
    "        x2, y2 = noise\n",
    "        total_dis = total_dis + math.dist(x0, noise)\n",
    "        Z.append(noise)\n",
    "\n",
    "    R = total_dis / n\n",
    "    return np.array(Z), R\n",
    "\n",
    "def generate_truncated_laplace_noise(X, epsilon): \n",
    "    Z = []\n",
    "    x_max = [np.max(X[:, 0]), np.max(X[:, 1])]\n",
    "    x_min = [np.min(X[:, 0]), np.min(X[:, 1])]\n",
    "    for x0 in X:\n",
    "        z, R = calculate_radius_with_noise(x0, 1, epsilon)\n",
    "        z = truncate(x_max, x_min, x0, z[0], epsilon)\n",
    "        Z.append(z)\n",
    "    return x_max, x_min, Z\n",
    "\n",
    "\n",
    "def truncate(x_max, x_min, x0, z, epsilon): \n",
    "    \"\"\"\n",
    "    x_max: max domain point (x, y)\n",
    "    x_min: min domain point (x, y)\n",
    "    x0: point to truncate (radius centre)\n",
    "    z: x0 + noise\n",
    "    epsilon: privacy budget\n",
    "    \"\"\"\n",
    "    x2, y2 = x_max\n",
    "    x1, y1 = x_min\n",
    "\n",
    "    zx, zy = z\n",
    "    if(x1 < zx < x2 and y1 < zy < y2): \n",
    "        # print('inside', x, y)\n",
    "        return z\n",
    "    else:\n",
    "        x, y = x0\n",
    "        z2 = generate_laplace_noise(epsilon, x, y)\n",
    "        return truncate(x_max, x_min, x0, z2, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.270071</td>\n",
       "      <td>0.293512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.351979</td>\n",
       "      <td>-0.510719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.487741</td>\n",
       "      <td>-0.318715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.819864</td>\n",
       "      <td>0.187774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.341477</td>\n",
       "      <td>1.457624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y\n",
       "0 -0.270071  0.293512\n",
       "1 -0.351979 -0.510719\n",
       "2  1.487741 -0.318715\n",
       "3 -0.819864  0.187774\n",
       "4 -0.341477  1.457624"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 0.5\n",
    "_, _, Z = generate_truncated_laplace_noise(X, eps)\n",
    "Z_scaled = pd.DataFrame(StandardScaler().fit_transform(Z), columns=['X', 'Y'])\n",
    "Z_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fc7d5fe0e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fc7d5fe0e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9086079144497976 [200 100 100 100 100 200 100 200 100 100 100 200 200 100 200 200 200 100\n",
      " 100 200 200 200 200 200 200 200 200 200 100 100 200 100 200 200 200 200\n",
      " 200 100 200 200 100 200 200 100 200 100 200 200 100 100] [100 200 100 100 100 200 100 100 100 200 100 200 200 100 200 100 100 100\n",
      " 100 200 100 200 100 100 100 200 100 200 100 100 200 100 100 100 200 100\n",
      " 200 100 100 200 100 200 200 100 200 100 100 100 100 100]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iterate_inclusion_and_write(algorithm, X_scaled, Z_scaled, y_true, r_emp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
