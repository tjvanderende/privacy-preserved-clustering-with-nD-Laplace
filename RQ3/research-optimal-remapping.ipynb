{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T19:01:10.093862Z",
     "start_time": "2023-09-08T19:01:08.434095Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tjibbevanderende/anaconda3/envs/notebook-thesis/lib/python3.8/site-packages/art/estimators/certification/__init__.py:14: UserWarning: PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.spatial as spatial\n",
    "from Helpers import helpers, twod_laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T19:06:19.179562Z",
     "start_time": "2023-09-08T19:06:19.130197Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../ExperimentRunners/data/nd-laplace/grid-nd-Laplace/heart-dataset/perturbed_0.5.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m plain_df, perturbed_df \u001B[38;5;241m=\u001B[39m \u001B[43mhelpers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_plain_and_perturbed_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimport_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../data/heart-dataset/heart_numerical.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m                                                                  \u001B[49m\u001B[43mperturbed_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../ExperimentRunners/data/nd-laplace/grid-nd-Laplace/heart-dataset/\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/notebook/Helpers/helpers.py:80\u001B[0m, in \u001B[0;36mload_plain_and_perturbed_dataset\u001B[0;34m(epsilon, import_path, perturbed_path)\u001B[0m\n\u001B[1;32m     78\u001B[0m dataset_name2 \u001B[38;5;241m=\u001B[39m perturbed_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mperturbed_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(epsilon) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     79\u001B[0m dataset1 \u001B[38;5;241m=\u001B[39m load_dataset(dataset_name1)\n\u001B[0;32m---> 80\u001B[0m dataset2 \u001B[38;5;241m=\u001B[39m \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name2\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m dataset1, dataset2\n",
      "File \u001B[0;32m~/Documents/GitHub/notebook/Helpers/helpers.py:71\u001B[0m, in \u001B[0;36mload_dataset\u001B[0;34m(datasetname, seperator)\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_dataset\u001B[39m(datasetname, seperator\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m---> 71\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdatasetname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseperator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     72\u001B[0m     df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mloc[:, \u001B[38;5;241m~\u001B[39mdf\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mcontains(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m^Unnamed\u001B[39m\u001B[38;5;124m'\u001B[39m)]\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "File \u001B[0;32m~/anaconda3/envs/notebook-thesis/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m    899\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    900\u001B[0m     dialect,\n\u001B[1;32m    901\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    908\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m    909\u001B[0m )\n\u001B[1;32m    910\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 912\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/notebook-thesis/lib/python3.8/site-packages/pandas/io/parsers/readers.py:577\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    574\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    576\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 577\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    579\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    580\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/anaconda3/envs/notebook-thesis/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1407\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1404\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1406\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1407\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/notebook-thesis/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1661\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1659\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1660\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1661\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1662\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1663\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1664\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1665\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1666\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1667\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1668\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1669\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1670\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1671\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1672\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/anaconda3/envs/notebook-thesis/lib/python3.8/site-packages/pandas/io/common.py:859\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    854\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    855\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    856\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    857\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    858\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 859\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    860\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    861\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    862\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    863\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    866\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    867\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    868\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../ExperimentRunners/data/nd-laplace/grid-nd-Laplace/heart-dataset/perturbed_0.5.csv'"
     ]
    }
   ],
   "source": [
    "plain_df, perturbed_df = helpers.load_plain_and_perturbed_dataset(0.5, import_path=\"../data/heart-dataset/heart_numerical.csv\", \n",
    "                                                                  perturbed_path=\"../ExperimentRunners/data/nd-laplace/grid-nd-Laplace/heart-dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.834960Z"
    }
   },
   "outputs": [],
   "source": [
    "plain_df = plain_df.drop(columns=['class'])\n",
    "plain_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.836517Z"
    }
   },
   "outputs": [],
   "source": [
    "plain_df_2d = plain_df.loc[:, ['baseline value', 'histogram_min']]\n",
    "perturbed_df_2d = perturbed_df.loc[:, ['baseline value', 'histogram_min']]\n",
    "plain_df_2d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.837813Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def get_Z_outside_domain_X(plain_df, perturbed_df):\n",
    "    \"\"\"tree = spatial.KDTree(plain_df)\n",
    "    # Query the KDTree with dataset1 to find the closest points in dataset2\n",
    "    _, closest_indices = tree.query(perturbed_df)\n",
    "    # Check if each point in dataset1 is within the domain of dataset2\n",
    "    in_domain = np.logical_and.reduce([np.logical_and(perturbed_df[:, dim] >= plain_df[:, dim].min(), perturbed_df[:, dim] <= plain_df[:, dim].max()) for dim in range(perturbed_df.shape[1])])\n",
    "\n",
    "    # Create a mask for points outside the domain of dataset2\n",
    "    outside_domain_mask = np.logical_not(in_domain)\n",
    "    return outside_domain_mask\"\"\"\n",
    "    outside_domain_mask = np.logical_or.reduce([np.logical_or(perturbed_df[:, dim] <= plain_df[:, dim].min(), perturbed_df[:, dim] >= plain_df[:, dim].max()) for dim in range(perturbed_df.shape[1])])\n",
    "    return outside_domain_mask\n",
    "\n",
    "def get_radius_and_perturbation(plain_df, epsilon):\n",
    "    data = {'r': [], 'x': [], 'y': []}\n",
    "    # loop through each record\n",
    "    for row in plain_df.values:\n",
    "        p = random.random()\n",
    "        theta = np.random.rand()*np.pi*2\n",
    "        r = twod_laplace.inverseCumulativeGamma(epsilon, p) # draw radius distance\n",
    "        private_point = twod_laplace.addVectorToPoint(row, r, theta)\n",
    "        data['r'].append(r)\n",
    "        data['x'].append(private_point[0])\n",
    "        data['y'].append(private_point[1])\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def transform(dataframe: pd.DataFrame, scaler: MinMaxScaler):\n",
    "    return pd.DataFrame(scaler.fit_transform(dataframe), columns=dataframe.columns)\n",
    "\n",
    "def inverse_transform(dataframe: pd.DataFrame, scaler: MinMaxScaler):\n",
    "    return pd.DataFrame(scaler.inverse_transform(dataframe), columns=dataframe.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.839297Z"
    }
   },
   "outputs": [],
   "source": [
    "tree = spatial.KDTree(plain_df_2d)\n",
    "query_data = tree.query_ball_point([132.0,4.0], r=0.3)\n",
    "plain_df_2d.iloc[query_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.840683Z"
    }
   },
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler(feature_range=[-1,1])\n",
    "min_max_scaler_perturbed = MinMaxScaler(feature_range=[-1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.841902Z"
    }
   },
   "outputs": [],
   "source": [
    "perturbed_data_with_r = get_radius_and_perturbation(plain_df_2d, 0.5)\n",
    "perturbed_data_with_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.843182Z"
    }
   },
   "outputs": [],
   "source": [
    "outside_domain_mask = get_Z_outside_domain_X(plain_df_2d.values, perturbed_data_with_r.drop(columns=['r']).values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.844506Z"
    }
   },
   "outputs": [],
   "source": [
    "perturbed_data_with_r_outside_domain = perturbed_data_with_r.drop(columns=['r'])[outside_domain_mask]\n",
    "perturbed_data_with_r_outside_domain = pd.concat([perturbed_data_with_r['r'][outside_domain_mask], perturbed_data_with_r_outside_domain], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T19:01:10.846352Z",
     "start_time": "2023-09-08T19:01:10.845774Z"
    }
   },
   "outputs": [],
   "source": [
    "perturbed_data_with_r_outside_domain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.847054Z"
    }
   },
   "outputs": [],
   "source": [
    "# perturbed_data_with_r_outside_domain_scaled = pd.DataFrame(min_max_scaler.fit_transform(perturbed_data_with_r_outside_domain), columns=perturbed_data_with_r_outside_domain.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.848367Z"
    }
   },
   "outputs": [],
   "source": [
    "random_point = perturbed_data_with_r_outside_domain.iloc[2]\n",
    "plain_tree = spatial.KDTree(plain_df_2d)\n",
    "perturbed_query_data = plain_tree.query_ball_point([random_point['x'], random_point['y']], r=random_point['r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.849545Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plain_df_2d.plot(kind='scatter', x='baseline value', y='histogram_min', color='blue', ax=ax)\n",
    "plain_df_2d.iloc[perturbed_query_data].plot(kind='scatter', x='baseline value', y='histogram_min', color='red', ax=ax)\n",
    "perturbed_data_with_r_outside_domain.plot(kind='scatter', x='x', y='y', color='green', ax=ax)\n",
    "ax.add_patch(plt.Circle((random_point['x'], random_point['y']), random_point['r'], color='black', fill=False))\n",
    "ax.scatter(random_point['x'], random_point['y'], color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.850931Z"
    }
   },
   "outputs": [],
   "source": [
    "perturbed_data_with_r_remapped = helpers.truncate_n_dimensional_laplace_noise(perturbed_data_with_r.drop(columns=['r']).values, plain_df_2d.values, grid_size=10, columns=['x', 'y'], include_indicator=True)\n",
    "# perturbed_data_with_r_remapped = pd.DataFrame(perturbed_data_with_r_remapped, columns=['baseline value', 'histogram_min'])\n",
    "perturbed_data_with_r_remapped = pd.concat([perturbed_data_with_r['r'], perturbed_data_with_r_remapped], axis=1)\n",
    "perturbed_data_with_r_outside_domain_remapped = perturbed_data_with_r_remapped[perturbed_data_with_r_remapped['is_remapped']]\n",
    "print(perturbed_data_with_r_remapped.shape, perturbed_data_with_r_outside_domain_remapped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.852509Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"perturbed_data_with_r_outside_domain_remapped = pd.concat([perturbed_data_with_r['r'][outside_domain_mask], perturbed_data_with_r_outside_domain_remapped], axis=1)\n",
    "perturbed_data_with_r_outside_domain_remapped.rename(columns={'baseline value': 'x', 'histogram_min': 'y'}, inplace=True)\n",
    "perturbed_data_with_r_outside_domain_remapped.head()\"\"\"\n",
    "perturbed_data_with_r_remapped.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.853983Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plain_df_2d.plot(kind='scatter', x='baseline value', y='histogram_min', color='blue', ax=ax)\n",
    "perturbed_data_with_r_outside_domain_remapped.plot(kind='scatter', x='x', y='y', color='red', ax=ax, alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.855238Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy.spatial as spatial\n",
    "\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    #return spatial.distance.euclidean(point1, point2)  # Euclidean distance as an example\n",
    "    return np.linalg.norm(point1 - point2)\n",
    "\n",
    "def remap_point(x, z_popularity, fake_data, real_data, radius, epsilon, plain_tree, w_x):\n",
    "    w_x = len(w_x) + len(z_popularity)\n",
    "    #w_q_sum = sum([len(calculate_popularity(q, real_data, radius)) for q in Q_r(x, z, real_data, radius)])\n",
    "    q = Q_r(x, real_data, radius, plain_tree)\n",
    "    w_q_sum = len(q)\n",
    "\n",
    "    # q_calc = (w_q_sum * math.exp(-epsilon * calculate_distance(q, z)))\n",
    "    #print(w_q_sum)\n",
    "    distance_xz = calculate_distance(x, fake_data)\n",
    "    #epsilon_offset = 1e-6  # Small offset to avoid division by zero or infinite results\n",
    "    \n",
    "    remapped_value = (w_x * math.exp(-epsilon * distance_xz)) / w_q_sum if w_q_sum > 0 else 0\n",
    "    \n",
    "    return remapped_value\n",
    "\n",
    "def Q_r(x, points, radius, kd_tree=None):\n",
    "    kdtree = spatial.KDTree(points) if kd_tree is None else kd_tree\n",
    "    indices = kdtree.query_ball_point((x), radius)\n",
    "    return [points[i] for i in indices]\n",
    "\n",
    "def find_new_r_for_perturbed_datas_outside_domain(perturbed_data: pd.DataFrame, plain_df: pd.DataFrame, epsilon=0.1):\n",
    "    tree = spatial.KDTree(plain_df)\n",
    "    perturbed_data_with_Q = perturbed_data.copy()\n",
    "    for index, point in perturbed_data_with_Q.iterrows():\n",
    "        x = plain_df.iloc[index]\n",
    "        new_r = { 'x_new': [], 'y_new': []}\n",
    "        for column in ['x', 'y']:\n",
    "            #print(point[column], x[column])\n",
    "            polularity_x = Q_r([x[column]], [point[column]], plain_df[column].values, point['r'], plain_tree)\n",
    "            #new_r[f\"{column}_new\"].append(remap_point([plain_df.loc[index,column]], [point[column]], plain_df[column].values, point['r'], epsilon, tree, w_x=polularity_x))\n",
    "            for x_q in polularity_x:\n",
    "                print(x_q)\n",
    "                new_r[f\"{column}_new\"].append(remap_point([plain_df.loc[x_q, column]], [point[column]], plain_df[column].values, point['r'], epsilon, tree, w_x=polularity_x))\n",
    "\n",
    "            coefficients = [x_new * x[column] for x_new in new_r[f\"{column}_new\"]] \n",
    "            sum_coefficients = sum(coefficients)\n",
    "            \n",
    "            probabilities = [coeff / sum_coefficients for coeff in coefficients]\n",
    "            if(sum_coefficients > 0): \n",
    "                averaged = np.average(polularity_x, axis=0, weights=probabilities)\n",
    "                averaged = averaged if averaged is not np.nan else point[column]\n",
    "                perturbed_data_with_Q.loc[index, f\"{column}_new\"] = averaged\n",
    "            else:\n",
    "                perturbed_data_with_Q.loc[index, f\"{column}_new\"] = point[column]\n",
    "        \n",
    "    return perturbed_data_with_Q; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.856574Z"
    }
   },
   "outputs": [],
   "source": [
    "plain_df_2d.head()\n",
    "plain_df_2d_renamed = plain_df_2d.rename(columns={'baseline value': 'x', 'histogram_min': 'y'}, inplace=False)\n",
    "plain_df_2d_renamed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.857982Z"
    }
   },
   "outputs": [],
   "source": [
    "# counts = find_new_r_for_perturbed_datas_outside_domain(perturbed_data_with_r_outside_domain_remapped.drop(columns=['is_remapped']), plain_df_2d_renamed, epsilon=0.5)\n",
    "\n",
    "#counts = counts.where(counts['Q_r'] > 0).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T19:01:10.881971Z",
     "start_time": "2023-09-08T19:01:10.860068Z"
    }
   },
   "outputs": [],
   "source": [
    "#counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.860501Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(counts['y_new'].max(), plain_df_2d_renamed['y'].max(), counts['y_new'].min(), plain_df_2d_renamed['y'].min(), perturbed_data_with_r_outside_domain_remapped['y'].max(), perturbed_data_with_r_outside_domain_remapped['y'].min())\n",
    "#print(counts['x_new'].max(), plain_df_2d_renamed['x'].max(), counts['x_new'].min(), plain_df_2d_renamed['x'].min(), perturbed_data_with_r_outside_domain_remapped['x'].max(), perturbed_data_with_r_outside_domain_remapped['x'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.862164Z"
    }
   },
   "outputs": [],
   "source": [
    "plain_df_2d_renamed.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$  \\sigma(x) = \\frac{w(x)e^{-\\epsilon d(x, z)}}{w(q)e^{-\\epsilon d(q, z)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.863644Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"fig, ax = plt.subplots()\n",
    "plain_df_2d_renamed.plot(kind='scatter', x='x', y='y', color='blue', ax=ax, alpha=0.1)\n",
    "\n",
    "counts.plot(kind='scatter', x='x_new', y='y_new', color='green', ax=ax)\n",
    "counts.plot(kind='scatter', x='x', y='y', color='red', ax=ax)\n",
    "ax.legend(['Plain', 'Optimal remapped', 'Grid-mapped (outside domain)'])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.865099Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_Z_outside_domain_X(plain_df, perturbed_df):\n",
    "    # tree = spatial.KDTree(plain_df)\n",
    "    # Query the KDTree with dataset1 to find the closest points in dataset2\n",
    "    # _, closest_indices = tree.query(perturbed_df)\n",
    "    # Check if each point in dataset1 is within the domain of dataset2\n",
    "    in_domain = np.logical_and.reduce([np.logical_and(perturbed_df[:, dim] >= plain_df[:, dim].min(), perturbed_df[:, dim] <= plain_df[:, dim].max()) for dim in range(perturbed_df.shape[1])])\n",
    "\n",
    "    # Create a mask for points outside the domain of dataset2\n",
    "    outside_domain_mask = np.logical_not(in_domain)\n",
    "    return outside_domain_mask\n",
    "\n",
    "\"\"\"\n",
    "    Optimal remapping algoritm.\n",
    "    Important: Should have a \"r\" (radius/ radial distance) which is used to remap the data.\n",
    "    @param perturbed_data: The perturbed data to be remapped. It should be grid-mapped already.\n",
    "    @param plain_df: The plain data to be used for remapping. (Used to determine crowdness)\n",
    "\"\"\"\n",
    "def optimal_remapping (perturbed_data: pd.DataFrame, plain_df: pd.DataFrame, epsilon=0.1):\n",
    "    tree = spatial.KDTree(plain_df)\n",
    "    perturbed_data_copy = perturbed_data.copy()\n",
    "    if perturbed_data.columns.isin(['is_remapped']).any():\n",
    "        perturbed_data_copy = perturbed_data_copy[perturbed_data_copy['is_remapped']]\n",
    "        perturbed_data_copy = perturbed_data_copy.drop(columns=['is_remapped'])\n",
    "    if not perturbed_data_copy.columns.isin(['r']).any():\n",
    "        raise ValueError(\"Perturbed data should have a column named 'r' which is the radius of the grid.\")\n",
    "    if not perturbed_data_copy.shape[1] -1 is plain_df.shape[1]:\n",
    "        raise ValueError(\"Perturbed data should have the same number of columns as plain data.\")\n",
    "    if not perturbed_data_copy.columns.drop(labels=['r']).isin(plain_df.columns).all():\n",
    "        raise ValueError(\"Perturbed data should have the same columns as plain data.\")\n",
    "\n",
    "    \n",
    "    ##truncated_perturbed_data = helpers.truncate_n_dimensional_laplace_noise(perturbed_data_copy, epsilon)\n",
    "    for index, private_data_point in perturbed_data_copy.iterrows(): # loop through each point outside the domain\n",
    "        non_private_data_point = plain_df.iloc[index] # get the corresponding plain data point\n",
    "        list_sigma = []\n",
    "        #print(non_private_data_point, private_data_point)\n",
    "        # calculate w_x\n",
    "        polularity_x = Q_r(non_private_data_point.values, plain_df.values, private_data_point['r'], tree)\n",
    "        popularity_z = Q_r(private_data_point[plain_df.columns].values, plain_df.values, private_data_point['r'], tree)\n",
    "        # for every point in a radius r around the non-private data point, calculate the new r.\n",
    "        for x_q in polularity_x:\n",
    "            #print(x_q)\n",
    "            # new_r[f\"{column}_new\"].append(remap_point([plain_df.loc[x_q, column]], [point[column]], plain_df[column].values, point['r'], epsilon, tree, w_x=polularity_x))\n",
    "            list_sigma.append(remap_point(x_q, popularity_z, private_data_point[plain_df.columns].values, plain_df.values, private_data_point['r'], epsilon, tree, w_x=polularity_x))\n",
    "\n",
    "        coefficients = [x_new * non_private_data_point for x_new in list_sigma] \n",
    "        #print(coefficients)\n",
    "        sum_coefficients = sum(coefficients)\n",
    "        \n",
    "        probabilities = np.array([coeff / sum_coefficients for coeff in coefficients]) # calculate the probabilities using the coefficients\n",
    "        if(sum_coefficients[sum_coefficients > 0].all()):\n",
    "            perturbed_data_copy.loc[index, plain_df.columns] = np.average(polularity_x, axis=0, weights=probabilities) # calculate the new value for the point based on the average with weightes probabilities.\n",
    "        #print(np.array(probabilities))\n",
    "\n",
    "    return perturbed_data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.866344Z"
    }
   },
   "outputs": [],
   "source": [
    "#perturbed_data_with_r_remapped = helpers.truncate_n_dimensional_laplace_noise(perturbed_data_with_r.drop(columns=['r']).values, plain_df_2d.values, grid_size=10)\n",
    "#perturbed_data_with_r_remapped = pd.DataFrame(perturbed_data_with_r_remapped, columns=['x', 'y'])\n",
    "#perturbed_data_with_r_remapped = pd.concat([perturbed_data_with_r['r'], perturbed_data_with_r_remapped], axis=1)\n",
    "perturbed_data_with_r_remapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.867874Z"
    }
   },
   "outputs": [],
   "source": [
    "optimal_remapped_data = optimal_remapping(perturbed_data_with_r_remapped, plain_df_2d_renamed, epsilon=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.869165Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "optimal_remapped_data.plot(kind='scatter', x='x', y='y', color='green', ax=ax, alpha=1)\n",
    "plain_df_2d_renamed.plot(kind='scatter', x='x', y='y', color='blue', ax=ax, alpha=0.1)\n",
    "perturbed_data_with_r_outside_domain_remapped.plot(kind='scatter', x='x', y='y', color='red', ax=ax, alpha=0.1)\n",
    "ax.legend(['Optimal remapped', 'Non-private', 'Grid-mapped (outside domain)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.870412Z"
    }
   },
   "outputs": [],
   "source": [
    "plain_df_2d_renamed.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.871738Z"
    }
   },
   "outputs": [],
   "source": [
    "def mechanism_design(plain_df, perturbed_df, grid_size=10, columns=['x', 'y'], epsilon=0.1):\n",
    "    perturbed_df_with_grid_remapping = helpers.truncate_n_dimensional_laplace_noise(perturbed_df.drop(columns=['r']).values, plain_df.values, grid_size=grid_size, columns=columns, include_indicator=True)\n",
    "    #perturbed_df_find_grid_remappings = perturbed_df_with_grid_remapping[perturbed_df_with_grid_remapping['is_remapped']]\n",
    "    perturbed_df_find_grid_remappings_with_r = pd.concat([perturbed_df['r'], perturbed_df_with_grid_remapping], axis=1)\n",
    "    perturbed_df_optimal_remapping = optimal_remapping(perturbed_df_find_grid_remappings_with_r, plain_df, epsilon=epsilon)\n",
    "    return perturbed_df_optimal_remapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.873256Z"
    }
   },
   "outputs": [],
   "source": [
    "perturbed_df_optimal_remapping = mechanism_design(plain_df_2d_renamed, perturbed_data_with_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.874725Z"
    }
   },
   "outputs": [],
   "source": [
    "perturbed_df_optimal_remapping.plot(kind='scatter', x='x', y='y', color='green', alpha=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.875751Z"
    }
   },
   "outputs": [],
   "source": [
    "plain_df_3d = plain_df.loc[:, ['baseline value', 'histogram_min', 'accelerations']]\n",
    "perturbed_df_3d = perturbed_df.loc[:, ['baseline value', 'histogram_min', 'accelerations']]\n",
    "perturbed_df_3d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.876954Z"
    }
   },
   "outputs": [],
   "source": [
    "from Helpers import threed_laplace\n",
    "\n",
    "epsilon = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.877817Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_3D_noise_for_dataset(plain_df:pd.DataFrame, epsilon):\n",
    "    Z = []\n",
    "    R = []\n",
    "    X = np.array(plain_df)\n",
    "    for x in X: \n",
    "        noise = generate_3D_noise(epsilon)\n",
    "        z = x + noise[:3]\n",
    "        Z.append(z)\n",
    "        R.append(noise[3])\n",
    "    return pd.concat((pd.DataFrame(Z, columns=plain_df.columns), pd.DataFrame(R, columns=['r'])), axis=1)\n",
    "def generate_3D_noise(epsilon): \n",
    "    polar_angle, azimuth, _ = threed_laplace.generate_unit_sphere() # theta, psi\n",
    "    r = threed_laplace.generate_r(epsilon)\n",
    "    # theta = 2 * np.pi * u[0]\n",
    "    #theta = np.random.rand() * np.pi\n",
    "    #phi = np.arccos(2 * u[1] - 1)\n",
    "    #phi = np.random.rand() * np.pi*2 # \n",
    "    # https://mathworld.wolfram.com/SphericalCoordinates.html formula 4/5/6\n",
    "    x = r * np.sin(polar_angle) * np.sin(azimuth)\n",
    "    y = r * np.sin(polar_angle) * np.cos(azimuth)\n",
    "    z = r * np.cos(polar_angle)\n",
    "    return x, y, z, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.878492Z"
    }
   },
   "outputs": [],
   "source": [
    "perturbed_df_3d = generate_3D_noise_for_dataset(plain_df_3d, epsilon)\n",
    "#perturbed_df_3d = pd.DataFrame(perturbed_df_3d, columns=['baseline value', 'histogram_min', 'accelerations'])\n",
    "perturbed_df_3d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.879183Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(plain_df_3d['baseline value'], plain_df_3d['histogram_min'], plain_df_3d['accelerations'], color='blue', alpha=0.1)\n",
    "ax.scatter3D(perturbed_df_3d['baseline value'], perturbed_df_3d['histogram_min'], perturbed_df_3d['accelerations'], color='red', alpha=0.1)\n",
    "#plain_df_3d.plot(kind='scatter', x='baseline value', y='histogram_min', color='blue', alpha=0.1, ax=ax)\n",
    "ax.legend(['Plain', 'Optimal remapped', 'Grid-mapped (outside domain)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.879880Z"
    }
   },
   "outputs": [],
   "source": [
    "perturbed_df_3d_grid_remapped = helpers.truncate_n_dimensional_laplace_noise(perturbed_df_3d.drop(columns=['r']).values, plain_df_3d.values, grid_size=10, columns=['baseline value', 'histogram_min', 'accelerations'], include_indicator=True)\n",
    "perturbed_df_3d_outside_domain = perturbed_df_3d[perturbed_df_3d_grid_remapped['is_remapped']]\n",
    "print(perturbed_df_3d_outside_domain.shape, perturbed_df_3d_grid_remapped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.880562Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "#ax.scatter3D(perturbed_df_3d_outside_domain['baseline value'], perturbed_df_3d_outside_domain['histogram_min'], perturbed_df_3d_outside_domain['accelerations'], color='blue', alpha=0.1)\n",
    "#ax.scatter3D(plain_df_3d['baseline value'], plain_df_3d['histogram_min'], plain_df_3d['accelerations'], color='green', alpha=0.1)\n",
    "ax.scatter3D(perturbed_df_3d_grid_remapped['baseline value'], perturbed_df_3d_grid_remapped['histogram_min'], perturbed_df_3d_grid_remapped['accelerations'], color='red', alpha=0.1)\n",
    "ax.legend(['Grid-mapped (outside domain)']) \n",
    "#ax.scatter3D(perturbed_df_3d_grid_remapped['baseline value'], perturbed_df_3d_grid_remapped['histogram_min'], perturbed_df_3d_grid_remapped['accelerations'], color='red', alpha=0.1)\n",
    "#perturbed_df_3d_grid_remapped.plot(kind='scatter', x='baseline value', y='histogram_min', color='blue', alpha=0.1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.881199Z"
    }
   },
   "outputs": [],
   "source": [
    "perturbed_df_remapped = mechanism_design(plain_df_3d, perturbed_df_3d, epsilon=0.5, columns=plain_df_3d.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.881769Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.scatter3D(perturbed_df_remapped['baseline value'], perturbed_df_remapped['histogram_min'], perturbed_df_remapped['accelerations'], color='green', alpha=1)\n",
    "ax.scatter3D(plain_df_3d['baseline value'], plain_df_3d['histogram_min'], plain_df_3d['accelerations'], color='blue', alpha=0.1)\n",
    "\n",
    "ax.legend(['Optimal remapped', 'Non-private', 'Grid-mapped (outside domain)'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying mechanism design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T19:01:10.892782Z",
     "start_time": "2023-09-08T19:01:10.882752Z"
    }
   },
   "outputs": [],
   "source": [
    "from Helpers import helpers \n",
    "\n",
    "plain_df, perturbed_df = helpers.load_plain_and_perturbed_dataset(0.5, import_path=\"../data/heart-dataset/heart_numerical.csv\", perturbed_path=\"../ExperimentRunners/data/nd-laplace-truncated/heart-dataset/\")\n",
    "plain_df = plain_df.drop(columns=['class'])\n",
    "plain_df_3d = plain_df.loc[:, ['baseline value', 'histogram_min', 'accelerations']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.883616Z"
    }
   },
   "outputs": [],
   "source": [
    "plain_df_3d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.884324Z"
    }
   },
   "outputs": [],
   "source": [
    "from Helpers.ldp_mechanism import ldp_mechanism\n",
    "\n",
    "mechanism = ldp_mechanism()\n",
    "private_dataset_3d = mechanism.randomise(non_private_dataset=plain_df_3d, epsilon=0.5, plot_validation=True)\n",
    "print(private_dataset_3d.shape, plain_df_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.884909Z"
    }
   },
   "outputs": [],
   "source": [
    "private_dataset_3d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.885541Z"
    }
   },
   "outputs": [],
   "source": [
    "plain_df_2d = plain_df.loc[:, ['baseline value', 'histogram_min']]\n",
    "plain_df_2d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.886152Z"
    }
   },
   "outputs": [],
   "source": [
    "private_dataset_2d = mechanism.randomise(plain_df_2d, plot_validation=True, epsilon=0.5)\n",
    "private_dataset_2d.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying with lower privacy budget (0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.886766Z"
    }
   },
   "outputs": [],
   "source": [
    "mechanism_more_private = ldp_mechanism()\n",
    "private_dataset_2d_more_private = mechanism_more_private.randomise(plain_df_2d, plot_validation=True, epsilon=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.887453Z"
    }
   },
   "outputs": [],
   "source": [
    "private_dataset_3d_more_private = mechanism_more_private.randomise(plain_df_3d, plot_validation=True, epsilon=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.888111Z"
    }
   },
   "outputs": [],
   "source": [
    "private_dataset_3d_more_private.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considering seeds dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.889212Z"
    }
   },
   "outputs": [],
   "source": [
    "from Helpers import helpers\n",
    "plain_seed_df, _ = helpers.load_plain_and_perturbed_dataset(0.5, import_path=\"../data/seeds-dataset/rq1.csv\", perturbed_path=\"../ExperimentRunners/data/nd-laplace-truncated/seeds-dataset/\")\n",
    "plain_seed_df_without_class = plain_seed_df.drop(columns=['class'])\n",
    "plain_seed_df_without_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.889959Z"
    }
   },
   "outputs": [],
   "source": [
    "from Helpers.ldp_mechanism import ldp_mechanism\n",
    "\n",
    "mechanism = ldp_mechanism()\n",
    "private_seed_dataset = mechanism.randomise(non_private_dataset=plain_seed_df_without_class, epsilon=0.5, plot_validation=True)\n",
    "print(private_seed_dataset.shape, plain_seed_df_without_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.890719Z"
    }
   },
   "outputs": [],
   "source": [
    "mechanism = ldp_mechanism()\n",
    "private_seed_dataset = mechanism.randomise(non_private_dataset=plain_seed_df_without_class, epsilon=0.1, plot_validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.891460Z"
    }
   },
   "outputs": [],
   "source": [
    "mechanism = ldp_mechanism()\n",
    "plain_seed_df_3d, _ = helpers.load_plain_and_perturbed_dataset(0.5, import_path=\"../data/seeds-dataset/rq2.csv\", perturbed_path=\"../ExperimentRunners/data/nd-laplace-truncated/seeds-dataset/\")\n",
    "plain_seed_df_3d_without_class  = plain_seed_df_3d.drop(columns=['class'])\n",
    "plain_seed_df_3d_without_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.892285Z"
    }
   },
   "outputs": [],
   "source": [
    "private_seed_dataset_3d = mechanism.randomise(non_private_dataset=plain_seed_df_3d_without_class, epsilon=0.5, plot_validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T19:01:10.913421Z",
     "start_time": "2023-09-08T19:01:10.893098Z"
    }
   },
   "outputs": [],
   "source": [
    "private_seed_dataset_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using nd-laplace\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import Helpers.helpers as helpers\n",
    "from Helpers.ldp_mechanism import ldp_mechanism\n",
    "\n",
    "plain_seed_df, _ = helpers.load_plain_and_perturbed_dataset(0.5, import_path=\"../data/seeds-dataset/rq2-nd.csv\", perturbed_path=\"../ExperimentRunners/data/nd-laplace-truncated/seeds-dataset/\")\n",
    "plain_seed_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.893749Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mech_nd = ldp_mechanism()\n",
    "plain_seed_df_no_class = plain_seed_df.drop(columns=['class'])\n",
    "plain_seed_df_no_class.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.894509Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "randomized_seed_df = mech_nd.randomise(non_private_dataset=plain_seed_df_no_class, epsilon=0.5, plot_validation=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.895386Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "randomized_seed_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.896267Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plain_seed_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.896925Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "randomized_seed_df_01 = mech_nd.randomise(non_private_dataset=plain_seed_df_no_class, epsilon=0.1, plot_validation=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.897544Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "randomized_seed_df_01.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.898163Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "randomized_seed_df_05 = mech_nd.randomise(non_private_dataset=plain_seed_df_no_class, epsilon=2, plot_validation=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.898793Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "randomized_seed_df_05.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.899488Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-08T19:01:10.900436Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
